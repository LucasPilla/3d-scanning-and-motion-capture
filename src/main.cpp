// main.cpp
// ---------
// Pipeline entry point.
// This only orchestrates the modules; all logic lives in separate classes.
// Steps:
//  1) Load video frames (VideoLoader)
//  2) Extract 2D joints using OpenPose (PoseDetector)
//  3) Fit SMPL to each frame (FittingOptimizer)
//  4) Visualize or export results (Visualization)

#include "VideoLoader.h"
#include "PoseDetector.h"
#include "Visualization.h"
#include "FittingOptimizer.h"
#include "TemporalSmoother.h"
#include "SMPLModel.h" 
#include "CameraModel.h"

#include <argparse/argparse.hpp>
#include <iostream>
#include <filesystem>
#include <Eigen/Dense>

int main(int argc, char* argv[])
{

    argparse::ArgumentParser program("pipeline");

    // Pipeline requires a video path
    program.add_argument("--video-path")
        .help("Path to video file")
        .required();

    // Pipeline requires a SMPL model path
    program.add_argument("--smpl-path")
        .help("Path to model generated by preprocess.py (.json)")
        .required();

    // Optional path to output folder
    // Default is "./output"
    program.add_argument("--output")
        .help("Output folder to save results.")
        .default_value("./output");

    // Optional path to pre-computed keypoints
    // If not defined, OpenPose will run for each frame
    program.add_argument("--precomputed-keypoints")
        .help("Path to pre-computed keypoints (.json)");

    try {
        // Parse args
        program.parse_args(argc, argv);
    }
    catch (const std::runtime_error& err) {
        // This block runs if the user forgets the argument
        std::cerr << err.what() << std::endl;
        std::cerr << program;
        std::exit(1);
    }

    // Load command line arguments into variables
    std::string videoPath = program.get("--video-path");

    std::string smplPath = program.get("--smpl-path");

    std::filesystem::path outputFolder = program.get("--output");

    std::optional<std::string> precomputedKeypointsPath = std::nullopt;
    if (program.is_used("--precomputed-keypoints"))
        precomputedKeypointsPath = program.get("--precomputed-keypoints");

    // Create output folder
    std::filesystem::create_directory(outputFolder);

    // Initialize video loader
    VideoLoader loader(videoPath);

    // Initialize pose detector
    PoseDetector poseDetector(precomputedKeypointsPath);

    // Initialize output video writer
    Visualization visualizer(loader.width(), loader.height(), loader.fps());

    // Initialize simple pinhole camera intrinsics (approximate)
    float fx = static_cast<float>(loader.width());
    float fy = static_cast<float>(loader.width()); // assume square pixels, fx ~ fy
    float cx = fx / 2.0f;
    float cy = static_cast<float>(loader.height()) / 2.0f;
    CameraModel camera(fx, fy, cx, cy);

    // Load SMPL model (preprocessed JSON).
    SMPLModel smplModel;
    if (!smplModel.loadFromJson(smplPath)) {
        std::cerr << "Warning: Failed to load SMPL model from " << smplPath << std::endl;
    }

    // Configure optimizer fitting options (flags).
    FittingOptimizer::Options fitOpts;
    fitOpts.temporalRegularization = false;
    fitOpts.warmStarting           = false;
    fitOpts.freezeShapeParameters  = false;

    // Initialize optimizer using SMPLModel instance
    FittingOptimizer fitter(&smplModel, fitOpts);

    int frameIdx = 0;
    cv::Mat frame;

    while (loader.readFrame(frame)) {

        frameIdx++;

        // // During initial development let's work with a small range of frames.
        // int startFrame = 1;
        // int endFrame   = 100;

        // if (frameCounter < startFrame) continue;
        // if (frameCounter >= endFrame) break;

        std::cout << "Processing frame " << frameIdx << "\n";

        // Extract pose
        Pose2D pose2D = poseDetector.detect(frame, frameIdx);

        // Run optimizer (currently a stub, just prepares data)
        fitter.fitFrame(pose2D);

        // Trigger SMPL forward pass once per frame with the current params
        SMPLMesh mesh = smplModel.getMesh();

        // Project SMPL joints to image using the camera model (debug visualization)
        Eigen::MatrixXf joints3D = smplModel.getJointPositions();

        // BODY_25 index for MidHip in OpenPose
        const int MID_HIP_2D = 8;
        const int ROOT_3D = 0; // SMPL root joint index

        bool canAlignRoot =
            joints3D.rows() > ROOT_3D &&
            pose2D.keypoints.size() > MID_HIP_2D &&
            pose2D.keypoints[MID_HIP_2D].score > 0.1f;

        Eigen::Vector3f offset = Eigen::Vector3f::Zero();

        if (canAlignRoot) {
            // 2D pelvis from OpenPose
            Point2D root2D = pose2D.keypoints[MID_HIP_2D];

            // Choose a nominal depth (meters) for the person
            float z0 = 3.0f;

            // Desired camera-space position of pelvis
            Eigen::Vector3f rootCam(
                (root2D.x - cx) / fx * z0,
                (root2D.y - cy) / fy * z0,
                z0
            );

            // Current SMPL root in model space
            Eigen::Vector3f smplRoot(
                joints3D(ROOT_3D, 0),
                joints3D(ROOT_3D, 1),
                joints3D(ROOT_3D, 2)
            );

            // Translation that maps SMPL root to desired camera position
            offset = rootCam - smplRoot;
        }

        for (int i = 0; i < joints3D.rows(); ++i) {
            Eigen::Vector3f pWorld(
                joints3D(i, 0),
                joints3D(i, 1),
                joints3D(i, 2)
            );

            // Apply global translation so root matches OpenPose pelvis
            Eigen::Vector3f pCam = pWorld + offset;

            if (pCam.z() <= 0.0f) {
                continue;
            }

            Eigen::Vector2f p2D = camera.project(pCam);
            cv::Point pt2D(
                static_cast<int>(p2D.x()),
                static_cast<int>(p2D.y())
            );

            cv::circle(frame, pt2D, 3, cv::Scalar(255, 0, 0), -1);
        }

        // // Save mesh
        // std::ostringstream meshFilename;
        // meshFilename << std::setw(6) << std::setfill('0') << frameIdx << ".obj";
        // std::filesystem::path meshPath = outputFolder / meshFilename.str();
        // mesh.save(meshPath);
    
        // Write output frame
        visualizer.drawKeypoints(frame, pose2D.keypoints);
        visualizer.write(frame);
    }

    std::cout << "Output written to output.mp4\n";

    return 0;
}